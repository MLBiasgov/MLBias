# Census/xD Bias Resource Repository

[![CircleCI Build Status](https://img.shields.io/circleci/build/gh/uswds/uswds/develop?style=for-the-badge&logo=circleci)](https://circleci.com/gh/uswds/uswds/tree/develop) ![Snyk vulnerabilities](https://img.shields.io/snyk/vulnerabilities/npm/uswds?style=for-the-badge) [![npm Version](https://img.shields.io/npm/v/uswds?style=for-the-badge)](https://www.npmjs.com/package/uswds) [![npm Downloads](https://img.shields.io/npm/dt/uswds?style=for-the-badge)](https://www.npmjs.com/package/uswds) [![GitHub issues](https://img.shields.io/github/issues/uswds/uswds?style=for-the-badge&logo=github)](https://github.com/uswds/uswds/issues) [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4?style=for-the-badge)](https://github.com/prettier/prettier)



The US Census Bureau xD team, in collaboration with the [10x](https://10x.gsa.gov) program, is building a library of machine learning and artificial intelligence resources to help combat bias introduced by bias and algorithms. 

WHY: AI and machine learning-based tools and techniques are quickly being adopted and deployed across governments at all levels. The rapid pace of adoptions raise ethical concerns of using these tools in civic settings, particularly when they could be invoked to make high-stakes decisions. Invisible quality issues in datasets, biased data collection methods, bad data governance problems, and issues in model development have the potential to introduce enormous bias into decision-making processes that adversely and systematically affect vulnerable populations served by government programs

WHAT: This collection currently includes a [syllabus for beginners, executable Jupyter Notebooks, an annotated list of resources, and other prototpye components](https://github.com/MLBiasgov/MLBias_papers). A full release is planned for 2021.


